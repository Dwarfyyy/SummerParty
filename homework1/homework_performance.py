import torch
import time
import numpy as np
from tabulate import tabulate

# Проверка доступности CUDA
device_cuda = torch.device("cuda" if torch.cuda.is_available() else "cpu")
cuda_available = torch.cuda.is_available()

# 3.1 Подготовка данных
# Создаем матрицы указанных размеров и заполняем их случайными числами
def create_matrices():
    sizes = [(64, 1024, 1024), (128, 512, 512), (256, 256, 256)]
    matrices = []
    for size in sizes:
        matrix = torch.rand(size)
        matrices.append((matrix, matrix.clone()))  # Две матрицы для операций
    return matrices, sizes

# 3.2 Функция измерения времени
# Измеряет время выполнения операций на CPU (time.time) и GPU (torch.cuda.Event)
def measure_time(operation, matrix_a, matrix_b, device, is_cuda=False):
    matrix_a = matrix_a.to(device)
    matrix_b = matrix_b.to(device)
    
    if is_cuda and cuda_available:
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        torch.cuda.synchronize()
        start_event.record()
        result = operation(matrix_a, matrix_b)
        end_event.record()
        torch.cuda.synchronize()
        elapsed_time = start_event.elapsed_time(end_event)
    else:
        start_time = time.time()
        result = operation(matrix_a, matrix_b)
        elapsed_time = (time.time() - start_time) * 1000  # Перевод в миллисекунды
    
    return elapsed_time, result

# 3.3 Сравнение операций
# Сравниваем время выполнения операций на CPU и GPU
def compare_operations():
    matrices, sizes = create_matrices()
    operations = {
        "Умножение матриц": lambda x, y: torch.matmul(x, y.transpose(-1, -2)),
        "Поэлементное сложение": lambda x, y: x + y,
        "Поэлементное умножение": lambda x, y: x * y,
        "Транспонирование": lambda x, y: x.transpose(-1, -2),
        "Суммирование": lambda x, y: x.sum()
    }
    
    results = []
    
    for size_idx, (matrix_a, matrix_b) in enumerate(matrices):
        size_str = f"Размер: {sizes[size_idx]}"
        results.append([size_str, "", "", ""])
        
        for op_name, op_func in operations.items():
            # Измерение времени на CPU
            cpu_time, _ = measure_time(op_func, matrix_a, matrix_b, torch.device("cpu"))
            
            # Измерение времени на GPU
            gpu_time = 0.0
            speedup = "Н/Д"
            if cuda_available:
                gpu_time, _ = measure_time(op_func, matrix_a, matrix_b, device_cuda, is_cuda=True)
                speedup = f"{cpu_time/gpu_time:.2f}x" if gpu_time > 0 else "Н/Д"
            
            results.append([op_name, f"{cpu_time:.2f}", f"{gpu_time:.2f}" if cuda_available else "Н/Д", speedup])
    
    # Вывод результатов в виде таблицы
    headers = ["Операция", "CPU (мс)", "GPU (мс)", "Ускорение"]
    print("\nРезультаты сравнения производительности:")
    print(tabulate(results, headers=headers, tablefmt="grid"))

# +==========================+============+============+=============+
# | Размер: (64, 1024, 1024) |            |            |             |
# +--------------------------+------------+------------+-------------+
# | Умножение матриц         | 670.56     | 1759.00    | 0.38x       |
# +--------------------------+------------+------------+-------------+
# | Поэлементное сложение    | 774.80     | 10.78      | 71.86x      |
# +--------------------------+------------+------------+-------------+
# | Поэлементное умножение   | 93.93      | 10.55      | 8.90x       |
# +--------------------------+------------+------------+-------------+
# | Транспонирование         | 0.36       | 0.07       | 4.87x       |
# +--------------------------+------------+------------+-------------+
# | Суммирование             | 19.55      | 23.85      | 0.82x       |
# +--------------------------+------------+------------+-------------+
# | Размер: (128, 512, 512)  |            |            |             |
# +--------------------------+------------+------------+-------------+
# | Умножение матриц         | 541.71     | 19.20      | 28.22x      |
# +--------------------------+------------+------------+-------------+
# | Поэлементное сложение    | 42.77      | 4.27       | 10.02x      |
# +--------------------------+------------+------------+-------------+
# | Поэлементное умножение   | 26.59      | 4.26       | 6.24x       |
# +--------------------------+------------+------------+-------------+
# | Транспонирование         | 0.02       | 0.05       | 0.45x       |
# +--------------------------+------------+------------+-------------+
# | Суммирование             | 6.25       | 1.42       | 4.41x       |
# +--------------------------+------------+------------+-------------+
# | Размер: (256, 256, 256)  |            |            |             |
# +--------------------------+------------+------------+-------------+
# | Умножение матриц         | 89.94      | 5.26       | 17.11x      |
# +--------------------------+------------+------------+-------------+
# | Поэлементное сложение    | 16.59      | 2.18       | 7.59x       |
# +--------------------------+------------+------------+-------------+
# | Поэлементное умножение   | 14.87      | 2.25       | 6.61x       |
# +--------------------------+------------+------------+-------------+
# | Транспонирование         | 0.02       | 0.09       | 0.18x       |
# +--------------------------+------------+------------+-------------+
# | Суммирование             | 3.55       | 0.82       | 4.31x       |
# +--------------------------+------------+------------+-------------+

if __name__ == "__main__":
    print(f"CUDA доступен: {cuda_available}")
    compare_operations()
    
# 3.4 Анализ результатов
# Проанализируйте результаты:

# - Какие операции получают наибольшее ускорение на GPU?

#Наибольшее ускорение на GPU достигается при поэлементном сложении больших матриц.(71.86x для размера 64x1024x1024).
#Матричное умножение демонстрирует хорошее ускорение для средних размеров (28.22x для 128x512x512), но замедляеться
# для самых больших матриц (0.38x).
#Поэлементные операции в целом работают быстрее на GPU с ускорением 6-10x для средних и малых матриц.
#Следовательно операции с вычислениями имеют преимущественное ускорение

# - Почему некоторые операции могут быть медленнее на GPU?

#Транспонирование показывает нестабильные результаты - ускорение 4.87x для больших матриц, но замедление 
#  (0.45x и 0.18x) для меньших размеров. 
#Суммирование ускоряется в 4-5 раз, кроме случая с самыми большими матрицами, где GPU работает медленнее (0.82x).
#Следовательно операции где нет необходимости в большом количестве вычислений могут быть медленнее из-за более 
# долгой загрузки и получения данных в GPU

# - Как размер матриц влияет на ускорение?

#Размер матриц существенно влияет на эффективность. Наибольшее ускорение достигается для средних размеров (128x512x512), 
#  в то время как для очень больших (64x1024x1024) некоторые операции выполняются медленнее из-за ограничений памяти
#  и накладных расходов. Значит чем больше размер матрицы, тем выше ускорение на GPU.

# - Что происходит при передаче данных между CPU и GPU?
#Копирование данных: Передача данных между CPU и GPU требует времени, так как данные копируются через шину PCIe. 
#Для коротких операций время копирования может превысить время вычислений, сводя на нет преимущества GPU.
#Оптимальная стратегия - минимизировать передачу данных и выполнять на GPU только достаточно сложные вычисления 
# над большими массивами данных.

