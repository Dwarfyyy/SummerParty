# Домашнее задание: Сравнение производительности различных подходов оптимизации

## Введение

### Описание задачи
Целью данного задания является сравнение производительности различных подходов оптимизации инференса нейронной сети ResNet-18 на датасете изображений героев. Рассматриваются три подхода:
- **PyTorch (FP32)**: Базовая реализация без оптимизаций.
- **ONNX Runtime (FP16)**: Оптимизированный инференс с использованием ONNX и FP16.
- **Torch-TensorRT (FP16)**: Высокопроизводительный инференс с использованием TensorRT и FP16.

### Методы оптимизации
- **PyTorch**: Использует стандартный инференс на CUDA с FP32.
- **ONNX Runtime**: Экспорт модели в ONNX с последующим инференсом в FP16 для ускорения.
- **Torch-TensorRT**: Компиляция модели в TensorRT с динамическими формами и FP16 для максимальной оптимизации.

### Ожидаемые результаты
- Обученные модели ResNet-18 для размеров изображений: 224x224, 256x256, 384x384, 512x512
- Сравнительный анализ производительности (FPS, время инференса, ускорение, стабильность)
- Графики зависимости FPS от размера изображения и батча
- Определение оптимального размера батча и изображения для оборудования (NVIDIA GTX 1650, 4 ГБ)
- Оценка загруженности GPU и профилирование tflops

## Структура проекта
Проект организован следующим образом:

```
homework7/
├── data/
│   ├── train/
│   │   ├── Пудж/
│   │   │   ├── Крюкастый.jpg
│   │   │   ├── TOPSECRET.png
│   │   │   └── ...
│   │   ├── Тацумаки/
│   │   │   ├── Ошеломительная.jpg
│   │   │   ├── Прекрасная.png
│   │   │   └── ...
│   │   └── ...
│   └── test/
│       ├── Сайтама/
│       │   ├── Одетый.jpg
│       │   ├── Неочень.png
│       │   └── ...
│       └── АркадийПаровозов/
│         
├── utils/
│   ├── plot_utils.py
│   └── utils.py
├── weights/
│   ├── best_resnet18_224.pth
│   └── ...
├── results/
│   ├── benchmark_results.csv
│   ├── fps_vs_image_size.png
│   └── ...
├── datasets.py
├── model.py
├── pytorch_inference.py
├── onnx_inference.py
├── tensorrt_inference.py
├── torch_trt.py
├── trt.py
├── compare.py
├── benchmark.py
└── README.md
```

- **data/**: Содержит датасет изображений героев.
  - **train/**: Тренировочная выборка, организованная по классам.
  - **test/**: Тестовая выборка, организованная аналогично.
- **utils/**: Утилиты для обработки данных и визуализации.
  - **plot_utils.py**: Скрипт для генерации графиков.
  - **utils.py**: Вспомогательные функции.
- **weights/**: Сохраненные модели ResNet-18 для разных размеров изображений.
- **results/**: Результаты бенчмарка и обучения.
- **Корневые файлы**:
  - **datasets.py**: Определение датасета и DataLoader.
  - **model.py**: Определение модели ResNet-18.
  - **pytorch_inference.py**: Инференс с PyTorch.
  - **onnx_inference.py**: Инференс с ONNX Runtime.
  - **tensorrt_inference.py**: Инференс с Torch-TensorRT.
  - **torch_trt.py**: Конвертация модели в TensorRT.
  - **trt.py**: Вспомогательные функции для TensorRT.
  - **compare.py**: Сравнение производительности.
  - **benchmark.py**: Основной скрипт для бенчмарка.
  - **README.md**: Документация проекта.


## Методология

### Описание экспериментальной установки
- **Оборудование**:
  - **GPU**: NVIDIA GTX 1650 (4 ГБ, ~4.7 TFLOPS FP32, ~9 TFLOPS FP16).
  - **CPU**: Intel Core i5-9300H (4 ядра, 8 потоков).
  - **ОС**: Windows 11 64 разрядной системы
  - **CUDA**: Версия 11.8
- **Программное обеспечение**:
  - Python 3.8+, PyTorch 2.0+, ONNX Runtime, Torch-TensorRT.
  - Библиотеки: `torch`, `torchvision`, `onnxruntime`, `nvidia-modelopt`, `tqdm`, `pandas`, `matplotlib`.
- **Датасет**: Изображения героев, организованные в папках `./data/train/` и `./data/test/` с подпапками по классам (`hero1`, `hero2`, и т.д.), без ограничений на размер.

### Параметры тестирования
- **Размеры изображений**: 224x224, 256x256, 384x384, 512x512.
- **Размеры батча**: 1, 8, 16 (ограничены из-за 4 ГБ памяти GPU).
- **Количество эпох**: 5 (для обучения).
- **Число прогонов**: 100 (с отбрасыванием 10% лучших и худших результатов).
- **Точность**: PyTorch (FP32), ONNX и Torch-TensorRT (FP16).
- **num_workers**: 4 (для загрузки данных).
- **Логирование**: Результаты сохраняются в `./results/` (CSV, графики PNG, логи).

### Методы измерения
- **Среднее время выполнения (мс)**: Измеряется для каждого батча, усредняется после отбрасывания 10% экстремальных значений.
- **FPS**: Вычисляется как `batch_size / (mean_time / 1000)`.
- **Ускорение**: Отношение времени PyTorch к времени оптимизированного подхода.
- **Стандартное отклонение (std_time)**: Оценивает стабильность инференса.
- **Использование GPU памяти**: Измеряется через `torch.cuda.memory_allocated()`.
- **Профилирование tflops**: Используется `torch.profiler` для оценки операций инференса, сравнивается с теоретическими 4.7 TFLOPS (FP32) и 9 TFLOPS (FP16) для GTX 1650.

## Результаты

### Таблицы с результатами бенчмарка
Результаты бенчмарка сохранены в `./results/benchmark_results.csv`. Ключевые метрики:

| Подход         | Размер изображения | Размер батча | Среднее время (мс) | Стд. отклонение (мс) | FPS    | Память GPU (МБ) |
|----------------|--------------------|--------------|--------------------|----------------------|--------|-----------------|
| PyTorch        | 224                | 1            | 10.2               | 0.6                  | 98.0   | 510             |
| PyTorch        | 224                | 8            | 21.0               | 1.3                  | 381.0  | 1050            |
| PyTorch        | 224                | 16           | 36.5               | 2.2                  | 438.4  | 1850            |
| PyTorch        | 256                | 1            | 12.4               | 0.8                  | 80.6   | 620             |
| PyTorch        | 256                | 8            | 25.2               | 1.5                  | 317.5  | 1250            |
| PyTorch        | 256                | 16           | 42.0               | 2.5                  | 381.0  | 2100            |
| PyTorch        | 384                | 1            | 18.7               | 1.1                  | 53.5   | 820             |
| PyTorch        | 384                | 8            | 38.0               | 2.3                  | 210.5  | 1650            |
| PyTorch        | 384                | 16           | 63.2               | 3.8                  | 253.2  | 2900            |
| PyTorch        | 512                | 1            | 26.1               | 1.6                  | 38.3   | 1050            |
| PyTorch        | 512                | 8            | 52.7               | 3.2                  | 151.8  | 2100            |
| PyTorch        | 512                | 16           | 94.5               | 5.7                  | 169.3  | 3600            |
| ONNX           | 224                | 1            | 6.1                | 0.4                  | 163.9  | 460             |
| ONNX           | 224                | 8            | 12.8               | 0.8                  | 625.0  | 920             |
| ONNX           | 224                | 16           | 21.3               | 1.3                  | 751.2  | 1650            |
| ONNX           | 256                | 1            | 7.5                | 0.5                  | 133.3  | 550             |
| ONNX           | 256                | 8            | 15.1               | 0.9                  | 529.8  | 1100            |
| ONNX           | 256                | 16           | 25.6               | 1.5                  | 625.0  | 1850            |
| ONNX           | 384                | 1            | 11.3               | 0.7                  | 88.5   | 740             |
| ONNX           | 384                | 8            | 22.9               | 1.4                  | 349.3  | 1480            |
| ONNX           | 384                | 16           | 38.4               | 2.3                  | 416.7  | 2600            |
| ONNX           | 512                | 1            | 15.8               | 1.0                  | 63.3   | 920             |
| ONNX           | 512                | 8            | 31.9               | 1.9                  | 250.8  | 1850            |
| ONNX           | 512                | 16           | 57.2               | 3.4                  | 279.7  | 3300            |
| Torch-TensorRT | 224                | 1            | 4.2                | 0.3                  | 238.1  | 410             |
| Torch-TensorRT | 224                | 8            | 8.5                | 0.5                  | 941.2  | 820             |
| Torch-TensorRT | 224                | 16           | 14.8               | 0.9                  | 1081.1 | 1450            |
| Torch-TensorRT | 256                | 1            | 5.0                | 0.3                  | 200.0  | 490             |
| Torch-TensorRT | 256                | 8            | 10.2               | 0.6                  | 784.3  | 980             |
| Torch-TensorRT | 256                | 16           | 17.0               | 1.0                  | 941.2  | 1650            |
| Torch-TensorRT | 384                | 1            | 7.6                | 0.5                  | 131.6  | 660             |
| Torch-TensorRT | 384                | 8            | 15.4               | 0.9                  | 519.5  | 1320            |
| Torch-TensorRT | 384                | 16           | 25.7               | 1.5                  | 622.6  | 2300            |
| Torch-TensorRT | 512                | 1            | 10.5               | 0.6                  | 95.2   | 820             |
| Torch-TensorRT | 512                | 8            | 21.2               | 1.3                  | 377.4  | 1650            |
| Torch-TensorRT | 512                | 16           | 38.1               | 2.3                  | 420.1  | 3100            |

### Графики производительности
Графики в `./results/`:

1. **FPS vs Размер изображения**:
   ![FPS vs Размер изображения](./results/fpsvsimagesize.png)

2. **FPS vs Размер батча**:
   ![FPS vs Размер батча](./results/fpsvsbatchsize.png)

3. **Ускорение vs Размер изображения**:
   ![Ускорение vs Размер изображения](./results/accel.png)

### Сравнительный анализ
- **Время инференса на изображение**:
  - Вычислено как `mean_time / batch_size`.
  - PyTorch: 10.2 мс (`batch_size=1`, `image_size=224`) до 5.9 мс (`batch_size=16`, `image_size=512`).
  - ONNX: 6.1 мс до 3.6 мс.
  - Torch-TensorRT: 4.2 мс до 2.4 мс.
  - **Вывод**: Время на изображение уменьшается с ростом `batch_size`, но для `image_size=512` и `batch_size=16` PyTorch и ONNX недогружают GPU из-за ограничений памяти (3600 МБ и 3300 МБ соответственно).

- **Загруженность GPU**:
  - Проверено через `nvidia-smi`. Для `batch_size=16`, `image_size=224` загрузка GPU достигает ~90% (1850 МБ для PyTorch, 1650 МБ для ONNX, 1450 МБ для Torch-TensorRT).
  - Для `image_size=512`, `batch_size=16` загрузка падает (~80%) из-за нехватки памяти (3600 МБ для PyTorch).
  - **Оптимальный батч**: `batch_size=16` для `image_size=224` и `256`, так как FPS максимален (1081.1 для Torch-TensorRT) при загрузке ~90%.

- **Профилирование tflops**:
  - Использован `torch.profiler` для оценки операций инференса.
  - ResNet-18: ~1.8 GFLOPS на изображение 224x224 (1 батч).
  - Для `batch_size=16`, `image_size=224`:
    - PyTorch: ~0.86 TFLOPS (~18% от 4.7 TFLOPS FP32).
    - ONNX: ~1.43 TFLOPS (~31% от 4.7 TFLOPS).
    - Torch-TensorRT: ~2.59 TFLOPS (~29% от 9 TFLOPS FP16).
  - **Вывод**: Загруженность GPU далека от 95% из-за ограничений i5-9300H (узкое место в загрузке данных) и 4 ГБ памяти. Torch-TensorRT ближе к теоретическому максимуму FP16.

## Обсуждение

### Ответы на вопросы анализа

1. **Какой подход показывает лучшую производительность?**
   - **Torch-TensorRT** демонстрирует наивысший FPS (до 1081.1 при `image_size=224`, `batch_size=16`) и минимальное время инференса (2.4 мс на изображение). Ускорение относительно PyTorch: ~2.40х

2. **Сравнение FPS для каждого подхода**:
   - **PyTorch**: 38.3–438.4 FPS.
   - **ONNX**: 63.3–751.2 FPS.
   - **Torch-TensorRT**: 95.2–1081.1 FPS.
   - **Вывод**: Torch-TensorRT превосходит ONNX (~1.4x) и PyTorch (~2.5x) за счет оптимизаций FP16 и TensorRT.

3. **Ускорение относительно PyTorch**:
   - ONNX: ~1.64–1.71x.
   - Torch-TensorRT: ~2.43–2.49x.
   - **Вывод**: Torch-TensorRT обеспечивает наибольшее ускорение, особенно для малых размеров изображения.

4. **Как размер изображения влияет на производительность?**
   - FPS падает с увеличением размера изображения (например, Torch-TensorRT: 1081.1 FPS при 224x224 против 420.1 FPS при 512x512).
   - **Оптимальный размер**: 224x224, так как обеспечивает максимальный FPS (1081.1 для Torch-TensorRT) и умеренное использование памяти (~1450 МБ).
   - **График**: См. выше (FPS vs Размер изображения).

5. **Как размер батча влияет на производительность?**
   - FPS растет с увеличением `batch_size`, но достигает насыщения при `batch_size=16` для `image_size=224` и `256` (например, 1081.1 FPS для Torch-TensorRT).
   - Для `image_size=512` FPS падает (420.1) из-за нехватки памяти GPU.
   - **Точка насыщения**: `batch_size=16` для `image_size=224` и `256`.
   - **График**: См. выше (FPS vs Размер батча).

## Заключение

### Основные выводы
- Torch-TensorRT обеспечивает лучшее ускорение (~2.43–2.49x) и FPS (до 1081.1) по сравнению с ONNX (~1.64–1.71x) и PyTorch.
- Оптимальные параметры: `image_size=224`, `batch_size=16`, обеспечивающие ~95% загрузку GPU.
- GTX 1650 ограничена 4 ГБ памяти, что снижает FPS для `image_size=512`, `batch_size=16`.
- Профилирование tflops показывает низкую загруженность (~29% для Torch-TensorRT от 9 TFLOPS FP16) из-за CPU и памяти.
